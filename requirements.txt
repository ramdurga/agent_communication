langchain>=0.2.0
langgraph>=0.2.0
langchain-core>=0.2.0

# Local LLM Options (install based on your choice):

# Option 1: Ollama (recommended for easy setup)
langchain-ollama>=0.1.0

# Option 2: vLLM (best for DGX - high performance)
# vllm>=0.4.0
langchain-openai>=0.1.0  # vLLM uses OpenAI-compatible API

# Option 3: HuggingFace direct loading
langchain-huggingface>=0.0.3
transformers>=4.40.0
torch>=2.0.0
accelerate>=0.27.0

# Option 4: LlamaCpp (for GGUF models)
# llama-cpp-python>=0.2.0

# Option 5: Text Generation Inference
# (uses langchain-huggingface)
